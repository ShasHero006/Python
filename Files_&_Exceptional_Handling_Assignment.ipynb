{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGpzngQRiNyCFYUgayZK5S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShasHero006/Python/blob/main/Files_%26_Exceptional_Handling_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q.1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where multiprocessing is a better choice.**\n",
        "\n",
        "Ans. Multithreading and multiprocessing are both techniques used to achieve parallelism in Python, but they have distinct use cases due to the differences in how they handle concurrency. Here's when each technique is preferable:\n",
        "\n",
        "**Multithreading -**\n",
        "\n",
        "When to use multithreading: Multithreading is more suitable for I/O-bound tasks, where the primary bottleneck is waiting for external resources like network responses, file I/O, or user input. Since I/O operations don't require the CPU to be active the entire time, multithreading can help utilize CPU resources more effectively while waiting for these operations to complete.\n",
        "\n",
        "Key scenarios for multithreading:\n",
        "\n",
        "I/O-bound operations: When tasks are waiting for external events (such as file operations, database queries, or network requests), multithreading can allow other threads to run while one is blocked, improving performance.\n",
        "\n",
        "Example: Web scraping, downloading multiple files, or reading from multiple files concurrently.\n",
        "\n",
        "Multiple tasks that can run simultaneously on shared memory: Multithreading allows threads to share the same memory space. If you have lightweight tasks that require communication between them, using threads can avoid the overhead of inter-process communication (IPC).\n",
        "\n",
        "Example: A GUI application where the main thread handles the interface, and other threads manage background tasks.\n",
        "\n",
        "When thread creation/management overhead is lower: Threads are generally lighter than processes in terms of resource usage, which makes multithreading preferable when you need to handle many concurrent tasks but don't require heavy CPU-bound work.\n",
        "\n",
        "Example: Handling multiple user requests in a web server.\n",
        "\n",
        "Advantages:\n",
        "\n",
        "Lightweight compared to processes.\n",
        "\n",
        "Suitable for tasks that don’t utilize the CPU heavily.\n",
        "\n",
        "Threads share memory, so communication between them is faster and simpler than with processes.\n",
        "\n",
        "Limitations:\n",
        "\n",
        "Python’s Global Interpreter Lock (GIL) limits CPU-bound multithreading in CPython, meaning only one thread can execute Python bytecode at a time.\n",
        "\n",
        " This makes multithreading ineffective for CPU-bound tasks.\n",
        "\n",
        "**Multiprocessing -**\n",
        "\n",
        "When to use multiprocessing: Multiprocessing is preferable for CPU-bound tasks, where the program is limited by the speed of the CPU. Since processes run in their own memory space and can utilize multiple CPU cores, multiprocessing is well-suited for parallelism in computationally intensive tasks.\n",
        "\n",
        "Key scenarios for multiprocessing:\n",
        "\n",
        "CPU-bound operations: If tasks require significant computational resources, such as performing large-scale numerical computations, video processing, machine learning model training, or scientific simulations, multiprocessing allows you to bypass the GIL and use multiple cores to speed up the work.\n",
        "\n",
        "Example: Image processing, matrix computations, complex data processing.\n",
        "\n",
        "Tasks that can run independently: Processes run in separate memory spaces, which makes them suitable when tasks don’t need to share memory or communicate frequently.\n",
        "\n",
        "Example: Batch processing of large datasets, where each process handles a separate portion of the data.\n",
        "\n",
        "Parallelism across multiple CPU cores: Multiprocessing can fully utilize all the cores of a CPU for parallelism, making it ideal for scenarios where multiple processes need to run truly in parallel.\n",
        "\n",
        "Example: Running multiple simulations or training machine learning models on separate parts of data.\n",
        "\n",
        "Advantages:\n",
        "\n",
        "Ideal for CPU-bound tasks because processes can run on multiple cores concurrently.\n",
        "\n",
        "Bypasses the GIL in Python, allowing full CPU utilization.\n",
        "\n",
        "Processes are isolated, preventing the shared-memory contention issues that can arise with threads.\n",
        "\n",
        "Limitations:\n",
        "\n",
        "Processes have more overhead (memory, CPU) compared to threads because each process runs in its own memory space.\n",
        "\n",
        "Communication between processes (via pipes, queues, etc.) is more complex and slower than communication between threads.\n",
        "\n",
        "Conclusion:\n",
        "\n",
        "Multithreading: Use for I/O-bound tasks where concurrency is needed, and tasks are lightweight or involve waiting for external resources (e.g., network I/O, file I/O).\n",
        "\n",
        "Multiprocessing: Use for CPU-bound tasks that require heavy computation and where you can take advantage of multiple CPU cores to execute tasks in parallel.\n",
        "\n",
        "\n",
        "\n",
        "___________________________________________________________________________"
      ],
      "metadata": {
        "id": "1w25LYF0VacX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q.2. Describe what a process pool is and how it helps in managing multiple processes efficiently.**\n",
        "\n",
        "Ans.A process pool is a mechanism used to manage and control a pool of worker processes, allowing for the efficient execution of tasks in parallel. The primary goal of a process pool is to reduce the overhead associated with creating and destroying processes by reusing a fixed number of processes for multiple tasks.\n",
        "\n",
        "How a Process Pool Works:\n",
        "\n",
        "A process pool contains a pre-defined number of worker processes that are created once and reused.\n",
        "\n",
        "The main program submits tasks (or jobs) to the pool, and the pool distributes these tasks among the available worker processes.\n",
        "\n",
        "Once a process completes its assigned task, it becomes idle and is ready to take on a new task, without needing to be recreated.\n",
        "\n",
        "This reduces the computational cost and time involved in creating new processes for each task, which is significant when there are many small tasks.\n",
        "\n",
        "Why Process Pools are Efficient:\n",
        "\n",
        "Reduced Overhead: Creating and destroying processes is an expensive operation in terms of CPU and memory. A process pool avoids this by keeping a fixed number of processes alive, which can be reused across multiple tasks.\n",
        "\n",
        "Task Scheduling and Load Balancing: The pool handles task scheduling internally, ensuring that the workload is distributed across available processes. This allows efficient utilization of system resources, avoiding scenarios where some processes are overloaded while others are idle.\n",
        "\n",
        "Concurrency: The pool enables true parallel execution of tasks (across multiple cores) since each process runs in its own memory space. This is especially useful in CPU-bound tasks where multiple cores can be utilized concurrently.\n",
        "\n",
        "Resource Management: By limiting the number of processes in the pool, you can control the amount of resources (like memory and CPU) consumed by the program, preventing excessive resource usage that could degrade system performance.\n",
        "\n",
        "Python Example:\n",
        "\n",
        " Using multiprocessing.Pool:\n",
        "\n",
        "In Python, the multiprocessing module provides the Pool class, which makes it easy to manage a pool of worker processes."
      ],
      "metadata": {
        "id": "BtP0Yi7Ya5lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "def square(x):\n",
        "    return x * x\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create a pool with 4 worker processes\n",
        "    with multiprocessing.Pool(processes=4) as pool:\n",
        "        # Map the function 'square' to the range of numbers (0 to 9)\n",
        "        results = pool.map(square, range(10))\n",
        "\n",
        "    print(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dK3_DR8tcWjm",
        "outputId": "9798d5aa-8864-409c-e3df-60da23cd051b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Features of Process Pools:\n",
        "\n",
        "Fixed Number of Workers: You can specify the number of processes (workers) to create in the pool. For example, if you have a quad-core machine, you can create 4 processes to utilize all CPU cores efficiently.\n",
        "\n",
        "Task Parallelism: The Pool.map() or Pool.apply_async() methods can be used to distribute tasks among the worker processes, running tasks concurrently.\n",
        "\n",
        "Graceful Process Management: The pool manages the lifecycle of processes efficiently. When tasks are finished, the processes remain alive (idle) until new tasks are available or the pool is closed.\n",
        "\n",
        "Advantages of Using Process Pools:\n",
        "\n",
        "Efficiency in Task Execution: The pool handles a large number of tasks more efficiently by reusing processes, rather than spawning and destroying them repeatedly.\n",
        "\n",
        "Parallelism on Multi-core Systems: By using a process pool, tasks can be distributed across multiple CPU cores, achieving real parallelism.\n",
        "\n",
        "Simplified Process Management: The Pool interface abstracts away much of the complexity of managing multiple processes, making it easier to use.\n",
        "\n",
        "Load Balancing: Tasks are dynamically assigned to worker processes, ensuring that all processes are optimally utilized.\n",
        "\n",
        "When to Use Process Pools:\n",
        "\n",
        "When you have a large number of independent tasks that need to run in parallel, and you want to manage system resources efficiently.\n",
        "\n",
        "For CPU-bound tasks where you need to leverage multiple cores for parallel processing.\n",
        "\n",
        "When creating and destroying processes frequently would be too costly in terms of performance.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "__________________________________________________________________________"
      ],
      "metadata": {
        "id": "d5qaKk2Kcfx3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q.3. Explain what multiprocessing is and why it is used in Python programs.**\n",
        "\n",
        "Ans.Multiprocessing in Python is a technique that allows the concurrent execution of multiple processes, each running in its own memory space. This enables Python programs to utilize multiple CPU cores for parallel execution, improving performance for CPU-bound tasks. The multiprocessing module in Python provides the necessary tools to create and manage processes, thereby bypassing Python's Global Interpreter Lock (GIL) and achieving true parallelism.\n",
        "\n",
        "Why Multiprocessing is Used:\n",
        "\n",
        "Bypass the Global Interpreter Lock (GIL):\n",
        "\n",
        "Python’s GIL prevents multiple native threads from executing Python bytecode simultaneously. This means that even in a multi-threaded program, only one thread can execute at a time in Python (though I/O-bound tasks can still benefit from threading).\n",
        "\n",
        "Multiprocessing circumvents this issue because each process runs its own Python interpreter instance with a separate memory space, meaning multiple processes can execute in parallel on different cores.\n",
        "\n",
        "Improving Performance for CPU-bound Tasks:\n",
        "\n",
        "CPU-bound tasks involve heavy computation, such as data processing, mathematical calculations, image processing, or simulations. For such tasks, Python’s multiprocessing allows these tasks to be distributed across multiple CPU cores, which increases throughput and reduces execution time.\n",
        "\n",
        "Without multiprocessing, these tasks would execute sequentially, taking longer to complete.\n",
        "\n",
        "Parallel Execution:\n",
        "\n",
        "Unlike multithreading, where threads share the same memory and execute concurrently, multiprocessing creates separate memory spaces for each process. This allows true parallelism, especially on multi-core systems, as each process can run independently on a different core.\n",
        "\n",
        "Key Features of Python's multiprocessing:\n",
        "\n",
        "Process Creation: The module allows creating new processes, similar to creating threads. Each process runs independently with its own memory space.\n",
        "\n",
        "Process Communication: Mechanisms like Queue, Pipe, and Manager enable inter-process communication (IPC). These tools allow processes to share data and messages safely.\n",
        "\n",
        "Process Synchronization: Locks, Semaphores, and Events can be used to synchronize processes when shared resources are involved.\n",
        "\n",
        "Pools of Workers: The Pool class manages a fixed number of worker processes to which tasks can be submitted, improving efficiency by reusing processes.\n",
        "\n",
        "Multiprocessing vs. Multithreading:\n",
        "\n",
        "Multithreading: Threads share the same memory space and are managed within a single process. This can lead to issues in Python due to the GIL, which allows only one thread to execute Python bytecode at a time.\n",
        "\n",
        "Multiprocessing: Each process has its own memory space and Python interpreter instance, meaning processes can truly run in parallel on multi-core processors without GIL limitations.\n",
        "\n",
        "How Multiprocessing Works in Python:\n",
        "\n",
        "When you create a new process using multiprocessing.Process, a new Python interpreter is instantiated, and the target function or code is executed within this separate process.\n",
        "\n",
        "Example of a Simple Multiprocessing Program:"
      ],
      "metadata": {
        "id": "BjXMDUtqdDqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "def worker_function(num):\n",
        "    print(f'Worker {num} is executing.')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create multiple processes\n",
        "    processes = []\n",
        "    for i in range(5):\n",
        "        process = multiprocessing.Process(target=worker_function, args=(i,))\n",
        "        processes.append(process)\n",
        "        process.start()  # Start the process\n",
        "\n",
        "    # Ensure all processes finish\n",
        "    for process in processes:\n",
        "        process.join()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-0T_1wSeTop",
        "outputId": "bae641b1-8840-4e41-8140-fee6b8f70788"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Worker 0 is executing.Worker 2 is executing.\n",
            "Worker 1 is executing.\n",
            "Worker 3 is executing.\n",
            "\n",
            "Worker 4 is executing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This program creates and starts five processes, each executing the worker_function concurrently. The join() ensures that the main process waits for all child processes to complete.\n",
        "\n",
        "Advantages of Multiprocessing:\n",
        "\n",
        "True Parallelism: On multi-core machines, multiple processes can run truly in parallel, taking advantage of multiple CPU cores.\n",
        "\n",
        "Better Performance for CPU-bound Tasks: It excels in situations where heavy computation needs to be parallelized.\n",
        "\n",
        "Bypassing the GIL: Since each process has its own interpreter and memory space, Python's GIL is not a constraint in multiprocessing.\n",
        "\n",
        "Disadvantages:\n",
        "\n",
        "Overhead of Process Creation: Creating processes is more expensive than creating threads due to the need to allocate separate memory and CPU resources.\n",
        "\n",
        "Memory Consumption: Each process has its own memory space, so data cannot be shared directly between processes (unlike threads). This can lead to higher memory consumption compared to multithreading.\n",
        "\n",
        "Complex Inter-Process Communication (IPC): Since processes don’t share memory, communication between them requires mechanisms like Queue or Pipe, which can introduce complexity and additional overhead.\n",
        "\n",
        "Conclusion:\n",
        "\n",
        "Multiprocessing is essential for Python programs that need true parallelism and better performance for CPU-bound tasks. It helps to fully utilize the capabilities of multi-core processors, bypasses the limitations of the GIL, and provides better control over parallel task execution. However, it comes with some overhead, such as memory consumption and process management, so it's essential to use it judiciously.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "__________________________________________________________________________\n"
      ],
      "metadata": {
        "id": "l7Q5hIx7ebSc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q.4.Write a Python program using multithreading where one thread adds numbers to a list, and another thread removes numbers from the list. Implement a mechanism to avoid race conditions using threading.Lock.**\n",
        "\n",
        "Ans. Here’s a Python program that uses multithreading where one thread adds numbers to a list and another thread removes numbers from the list. To avoid race conditions, threading.Lock is used to ensure that the operations on the shared list are properly synchronized."
      ],
      "metadata": {
        "id": "FT1CjhNDfCnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "\n",
        "# Shared list\n",
        "shared_list = []\n",
        "\n",
        "# Create a lock object to avoid race conditions\n",
        "list_lock = threading.Lock()\n",
        "\n",
        "# Function to add numbers to the list\n",
        "def add_to_list():\n",
        "    for i in range(10):\n",
        "        with list_lock:  # Locking the list to ensure exclusive access\n",
        "            shared_list.append(i)\n",
        "            print(f\"Added {i} to the list.\")\n",
        "        time.sleep(0.5)  # Simulate some work\n",
        "\n",
        "# Function to remove numbers from the list\n",
        "def remove_from_list():\n",
        "    for i in range(10):\n",
        "        with list_lock:  # Locking the list to ensure exclusive access\n",
        "            if shared_list:\n",
        "                removed_item = shared_list.pop(0)\n",
        "                print(f\"Removed {removed_item} from the list.\")\n",
        "            else:\n",
        "                print(\"List is empty, waiting for items to be added.\")\n",
        "        time.sleep(0.7)  # Simulate some work\n",
        "\n",
        "# Create the threads\n",
        "thread1 = threading.Thread(target=add_to_list)\n",
        "thread2 = threading.Thread(target=remove_from_list)\n",
        "\n",
        "# Start the threads\n",
        "thread1.start()\n",
        "thread2.start()\n",
        "\n",
        "# Wait for both threads to complete\n",
        "thread1.join()\n",
        "thread2.join()\n",
        "\n",
        "print(\"Final list state:\", shared_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptSSwnDkfkUE",
        "outputId": "386cd8f0-7b03-45d0-ffe8-a3f51b76e8b5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 0 to the list.\n",
            "Removed 0 from the list.\n",
            "Added 1 to the list.\n",
            "Removed 1 from the list.\n",
            "Added 2 to the list.\n",
            "Removed 2 from the list.\n",
            "Added 3 to the list.\n",
            "Added 4 to the list.\n",
            "Removed 3 from the list.\n",
            "Added 5 to the list.\n",
            "Removed 4 from the list.\n",
            "Added 6 to the list.\n",
            "Added 7 to the list.\n",
            "Removed 5 from the list.\n",
            "Added 8 to the list.\n",
            "Removed 6 from the list.\n",
            "Added 9 to the list.\n",
            "Removed 7 from the list.\n",
            "Removed 8 from the list.\n",
            "Removed 9 from the list.\n",
            "Final list state: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "Shared Resource: shared_list is the shared list that both threads operate on.\n",
        "\n",
        "Lock: A threading.Lock() is created to synchronize access to the list. This prevents race conditions when both threads try to access or modify the list at the same time.\n",
        "\n",
        "Adding to the List: The add_to_list() function adds numbers to the list while holding the lock to ensure no other thread modifies the list simultaneously.\n",
        "\n",
        "Removing from the List: The remove_from_list() function removes numbers from the list, also holding the lock to ensure exclusive access.\n",
        "\n",
        "Thread Execution: Two threads (thread1 and thread2) are created, one for adding and one for removing numbers from the list. Both threads are started, and the program waits for both threads to complete using join().\n",
        "\n",
        "Key Points:\n",
        "\n",
        "Locking Mechanism: The with list_lock: statement ensures that the critical section of the code (where the list is modified) is protected by the lock.\n",
        "\n",
        "Race Condition Prevention: The lock ensures that only one thread can modify the list at a time, avoiding race conditions.\n",
        "\n",
        "\n",
        "\n",
        "___________________________________________________________________________\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3LsBKXAFfyxn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q.5. Describe the methods and tools available in Python for safely sharing data between threads and processes.**\n",
        "\n",
        "Ans. Methods and tools for safe data sharing between threads and processes\n",
        "\n",
        "For Threads:\n",
        "\n",
        "1. Queues (queue.Queue): Thread-safe queues provide a mechanism for threads to exchange data in a synchronized manner.\n",
        "\n",
        " Producers add items to the queue, and consumers remove items.  This avoids race conditions when accessing shared data.\n"
      ],
      "metadata": {
        "id": "ibrs8GpAgJs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import queue\n",
        "import threading\n",
        "import time\n",
        "\n",
        "q = queue.Queue()\n",
        "\n",
        "def worker():\n",
        "  while True:\n",
        "    item = q.get()\n",
        "    print(f\"Processing item: {item}\")\n",
        "    time.sleep(1)\n",
        "    q.task_done()\n",
        "\n",
        "threading.Thread(target=worker, daemon=True).start()\n",
        "\n",
        "for item in range(10):\n",
        "  q.put(item)\n",
        "\n",
        "q.join() # Wait for all items to be processed\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yb8Rb23PjFyd",
        "outputId": "2ca3802f-0c2d-4ddb-abd5-29b32be7dedb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing item: 0\n",
            "Processing item: 1\n",
            "Processing item: 2\n",
            "Processing item: 3\n",
            "Processing item: 4\n",
            "Processing item: 5\n",
            "Processing item: 6\n",
            "Processing item: 7\n",
            "Processing item: 8\n",
            "Processing item: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Locks (threading.Lock):  A lock protects a shared resource, ensuring that only one thread can access it at a time.\n",
        "\n",
        " Use a context manager (`with lock:`) for proper acquisition and release."
      ],
      "metadata": {
        "id": "of08EMs8jTlm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lock = threading.Lock()\n",
        "counter = 0\n",
        "\n",
        "def increment_counter():\n",
        "    global counter\n",
        "    for _ in range(100000):\n",
        "        with lock:\n",
        "            counter += 1\n",
        "\n",
        "threads = []\n",
        "for _ in range(5):\n",
        "    thread = threading.Thread(target=increment_counter)\n",
        "    threads.append(thread)\n",
        "    thread.start()\n",
        "\n",
        "for thread in threads:\n",
        "    thread.join()\n",
        "\n",
        "print(f\"Counter: {counter}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Of7KRb5jeii",
        "outputId": "6e99048b-4ecd-4e3a-f29b-daa05334a2a4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter: 500000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 3. Condition Variables (threading.Condition): A condition variable allows threads to wait for a specific condition to become true before continuing execution.\n",
        "\n",
        " Useful for more complex synchronization scenarios.\n",
        "\n",
        "4. Semaphores (threading.Semaphore): Controls access to a shared resource by limiting the number of threads that can access it simultaneously.\n",
        "\n",
        "For Processes:\n",
        "\n",
        "1. Queues (multiprocessing.Queue): Similar to thread queues but designed for inter-process communication (IPC).\n",
        "\n",
        "2. Pipes (multiprocessing.Pipe): Creates a pipe for one-way or two-way communication between processes.\n",
        "\n",
        "3. Shared Memory (multiprocessing.Array, multiprocessing.Value): Shared memory allows processes to directly access the same memory location, but requires careful synchronization to avoid race conditions.\n",
        "\n",
        "  Use Value or Array for primitive data types or arrays, respectively.\n",
        "\n",
        "\n",
        "4. Managers (multiprocessing.Manager): Creates a server process that manages shared objects, making it easier to share more complex data structures (dictionaries, lists, etc.) between processes.  Provide a way to share data of any picklable type between processes.\n",
        "\n",
        " For complex data structures that require more advanced locking and coordination.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SDBBa7sMjpq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import random\n",
        "\n",
        "def worker_process(data_dict, num):\n",
        "  data_dict[num] = random.randint(1,100)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    with multiprocessing.Manager() as manager:\n",
        "\n",
        "      shared_dict = manager.dict()\n",
        "      processes = []\n",
        "\n",
        "      for i in range(5):\n",
        "          p = multiprocessing.Process(target=worker_process, args=(shared_dict, i))\n",
        "          processes.append(p)\n",
        "          p.start()\n",
        "\n",
        "      for p in processes:\n",
        "          p.join()\n",
        "\n",
        "      print(f\"Shared dictionary: {shared_dict}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeAwS-p-kf1H",
        "outputId": "bef75974-a08d-495d-c904-5964d5f19e10"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shared dictionary: {0: 77, 1: 37, 2: 73, 3: 6, 4: 58}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "___________________________________________________________________________"
      ],
      "metadata": {
        "id": "wvT49YqwkqBm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q.6. Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for doing so.**\n",
        "\n",
        "Ans. Handling exceptions in concurrent programs (whether using threads or processes) is crucial for several reasons:\n",
        "\n",
        "Why Handling Exceptions in Concurrent Programs is Crucial\n",
        "Prevents Unexpected Program Termination:\n",
        "\n",
        "In concurrent programs, if an exception occurs in a thread or process and is not handled properly, it can lead to premature termination of that thread or process. This can leave shared resources in an inconsistent state, cause data corruption, or prevent the completion of other tasks in the program.\n",
        "\n",
        "Ensures Data Integrity:\n",
        "\n",
        "Concurrent programs often share data or resources (e.g., files, databases, shared variables). If an exception occurs without being handled, data might be left in a corrupted or inconsistent state. This is especially dangerous in scenarios involving writing to shared memory, modifying files, or updating a database.\n",
        "\n",
        "Prevents Deadlocks or Resource Leaks:\n",
        "\n",
        "Threads and processes often acquire locks or other resources (like file handles, network connections). If an exception occurs while a thread or process holds a lock and is not handled, the lock might never be released, leading to deadlocks. Similarly, open files, network connections, or memory resources might not be properly closed, causing resource leaks.\n",
        "\n",
        "Maintains Program Responsiveness:\n",
        "\n",
        "In concurrent programs, especially in multi-threaded applications like web servers or GUIs, an unhandled exception can freeze the program or make it unresponsive. Proper exception handling ensures the program remains responsive and able to recover from errors gracefully.\n",
        "\n",
        "Graceful Shutdown:\n",
        "\n",
        "When exceptions occur, particularly in multiprocessing, it’s essential to handle them properly to ensure that all processes are terminated cleanly and resources are released. This avoids leaving orphan processes running or files locked.\n",
        "\n",
        "Debugging and Logging:\n",
        "\n",
        "Without proper exception handling, it may be difficult to track down where and why errors occurred in concurrent programs. Handling exceptions properly allows for logging errors, which can help in debugging and improving program reliability.\n",
        "\n",
        "Techniques for Handling Exceptions in Concurrent Programs\n",
        "\n",
        "Exception Handling in Threads\n",
        "\n",
        "Try-Except Blocks:\n",
        "\n",
        "In threading, exceptions raised within a thread can be caught using try-except blocks inside the thread’s target function. This prevents the thread from terminating unexpectedly.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "_-9wrduzksj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "def thread_function():\n",
        "    try:\n",
        "        # Perform some operation that may raise an exception\n",
        "        result = 10 / 0\n",
        "    except ZeroDivisionError as e:\n",
        "        print(f\"Handled exception in thread: {e}\")\n",
        "\n",
        "thread = threading.Thread(target=thread_function)\n",
        "thread.start()\n",
        "thread.join()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnPlVhe_l3d2",
        "outputId": "6229dd59-823f-458d-bd87-ffad1bfe41ea"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Handled exception in thread: division by zero\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thread-Level Exception Handling:\n",
        "\n",
        "Python’s threading module does not automatically propagate exceptions from a child thread back to the main thread. To capture exceptions across threads, you may need to implement custom handling mechanisms (e.g., passing exceptions back to the main thread using a queue).\n",
        "\n",
        "Thread Exception Propagation Using concurrent.futures:\n",
        "\n",
        "The concurrent.futures.ThreadPoolExecutor provides a way to handle exceptions in threads and propagate them to the main thread. If a thread raises an exception, the future object associated with it will capture the exception, and you can retrieve it using the .result() method.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "LxWcK7cAl_SI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "def faulty_function():\n",
        "    return 10 / 0  # Causes ZeroDivisionError\n",
        "\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    future = executor.submit(faulty_function)\n",
        "    try:\n",
        "        future.result()  # Will raise the exception here\n",
        "    except ZeroDivisionError as e:\n",
        "        print(f\"Exception caught: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8D8fKF5mMAS",
        "outputId": "0550dafb-2712-478e-89c3-ba5a89770225"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception caught: division by zero\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Exception Handling in Multiprocessing\n",
        "\n",
        "Try-Except Blocks in Processes:\n",
        "\n",
        "Just like in threads, processes should handle exceptions internally using try-except blocks. However, exceptions raised inside a process will not propagate back to the parent process automatically.\n",
        "\n",
        "Example :    \n"
      ],
      "metadata": {
        "id": "Ds3ndrLGmQGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process\n",
        "\n",
        "def process_function():\n",
        "    try:\n",
        "        result = 10 / 0  # Will cause ZeroDivisionError\n",
        "    except ZeroDivisionError as e:\n",
        "        print(f\"Handled exception in process: {e}\")\n",
        "\n",
        "p = Process(target=process_function)\n",
        "p.start()\n",
        "p.join()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLojtlL5maDG",
        "outputId": "cf1e7250-8b5c-4d59-f1d7-4af0c8756c4f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Handled exception in process: division by zero\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using concurrent.futures.ProcessPoolExecutor:\n",
        "\n",
        "Similar to ThreadPoolExecutor, the ProcessPoolExecutor in the concurrent.futures module allows exception propagation between processes. When calling .result() on a future object, any exceptions raised inside the process will be raised in the calling process.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "zXUqo4vNmkKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ProcessPoolExecutor\n",
        "\n",
        "def faulty_process():\n",
        "    return 10 / 0  # Causes ZeroDivisionError\n",
        "\n",
        "with ProcessPoolExecutor() as executor:\n",
        "    future = executor.submit(faulty_process)\n",
        "    try:\n",
        "        future.result()  # Will raise the exception here\n",
        "    except ZeroDivisionError as e:\n",
        "        print(f\"Exception caught: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_VJH06umtWc",
        "outputId": "6133b02c-e239-463c-8290-87100805db6c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception caught: division by zero\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using multiprocessing.Queue or Pipe for Exception Communication:\n",
        "\n",
        "In multiprocessing, you can use Queue or Pipe to pass exception information from child processes to the parent process. This allows capturing exceptions raised inside a process and handling them appropriately in the parent process.\n",
        "\n",
        "Example :     "
      ],
      "metadata": {
        "id": "tdsZ-BhumyPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process, Queue\n",
        "\n",
        "def process_function(q):\n",
        "    try:\n",
        "        result = 10 / 0\n",
        "    except ZeroDivisionError as e:\n",
        "        q.put(e)\n",
        "\n",
        "q = Queue()\n",
        "p = Process(target=process_function, args=(q,))\n",
        "p.start()\n",
        "p.join()\n",
        "\n",
        "exception = q.get()\n",
        "if exception:\n",
        "    print(f\"Exception in process: {exception}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M95V8HQanA_i",
        "outputId": "e016d175-3226-408b-c0c7-ee9879204b32"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception in process: division by zero\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary of Techniques for Exception Handling in Concurrency:\n",
        "\n",
        "Threads:\n",
        "\n",
        "Use try-except blocks within thread target functions.\n",
        "\n",
        "Use concurrent.futures.ThreadPoolExecutor to capture exceptions.\n",
        "\n",
        "Use synchronization primitives like Lock with try-finally to ensure proper resource management.\n",
        "\n",
        "Processes:\n",
        "\n",
        "Handle exceptions using try-except within process target functions.\n",
        "Use concurrent.futures.ProcessPoolExecutor for exception handling across processes.\n",
        "\n",
        "Use multiprocessing.Queue or Pipe for exception communication between processes.\n",
        "\n",
        "General:\n",
        "\n",
        "Always ensure resources (locks, files, connections) are released using finally blocks.\n",
        "\n",
        "Log exceptions using the logging module for debugging and tracking purposes.\n",
        "\n",
        "Proper exception handling in concurrent programs is essential to prevent resource leaks, maintain data integrity, avoid deadlocks, and ensure program stability.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "__________________________________________________________________________\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8mKTg6uZnHGz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q.7.Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently. Use concurrent.futures.ThreadPoolExecutor to manage the threads.**\n",
        "\n",
        "Ans. Here's an example of how you can use concurrent.futures.ThreadPoolExecutor to calculate the factorial of numbers from 1 to 10 concurrently:"
      ],
      "metadata": {
        "id": "RKtkHJ1BnbX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import concurrent.futures\n",
        "import math\n",
        "\n",
        "# Function to calculate the factorial of a given number\n",
        "def factorial(n):\n",
        "    return math.factorial(n)\n",
        "\n",
        "# List of numbers from 1 to 10\n",
        "numbers = list(range(1, 11))\n",
        "\n",
        "# Create a ThreadPoolExecutor to manage threads\n",
        "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "    # Submit tasks to the executor to calculate the factorial of each number\n",
        "    futures = [executor.submit(factorial, num) for num in numbers]\n",
        "\n",
        "    # Collect the results as they complete\n",
        "    for future in concurrent.futures.as_completed(futures):\n",
        "        try:\n",
        "            result = future.result()\n",
        "            print(f\"Factorial calculated: {result}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Exception occurred: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Buj3T-in_Da",
        "outputId": "afd688a8-3208-4468-dca0-8e3407d30f10"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Factorial calculated: 3628800\n",
            "Factorial calculated: 24\n",
            "Factorial calculated: 40320\n",
            "Factorial calculated: 2\n",
            "Factorial calculated: 5040\n",
            "Factorial calculated: 1\n",
            "Factorial calculated: 120\n",
            "Factorial calculated: 720\n",
            "Factorial calculated: 362880\n",
            "Factorial calculated: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "factorial function: This function calculates the factorial of a given number using math.factorial.\n",
        "\n",
        "ThreadPoolExecutor: Manages the threads for concurrent execution.\n",
        "\n",
        "executor.submit(): Submits each factorial calculation as a separate task to be run in a thread.\n",
        "\n",
        "as_completed(): Collects the results as soon as the tasks are done.\n",
        "\n",
        "future.result(): Retrieves the result of each completed task.\n",
        "\n",
        "This code will print the factorial of each number from 1 to 10, calculated concurrently using multiple threads.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "__________________________________________________________________________"
      ],
      "metadata": {
        "id": "7Hhcr_UCoGY4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q.8.  Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8 processes).**\n",
        "\n",
        "\n",
        "Ans. Here's a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. It also measures the time taken to perform the computation with different pool sizes (e.g., 2, 4, and 8 processes):"
      ],
      "metadata": {
        "id": "qCbC3ZQ1oWcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "# Function to compute the square of a given number\n",
        "def square(n):\n",
        "    return n * n\n",
        "\n",
        "# List of numbers from 1 to 10\n",
        "numbers = list(range(1, 11))\n",
        "\n",
        "# Function to compute squares using a multiprocessing Pool of given size\n",
        "def compute_squares(pool_size):\n",
        "    print(f\"\\nUsing pool size: {pool_size}\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Create a multiprocessing pool with the specified number of processes\n",
        "    with multiprocessing.Pool(pool_size) as pool:\n",
        "        # Use pool.map to apply the square function to each number in parallel\n",
        "        results = pool.map(square, numbers)\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Results: {results}\")\n",
        "    print(f\"Time taken: {end_time - start_time:.5f} seconds\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Measure time taken with different pool sizes\n",
        "    for pool_size in [2, 4, 8]:\n",
        "        compute_squares(pool_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6T1G1MOqmQP",
        "outputId": "c6502f68-d8db-4998-e1fe-daa24eebc2d7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using pool size: 2\n",
            "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.03325 seconds\n",
            "\n",
            "Using pool size: 4\n",
            "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.05187 seconds\n",
            "\n",
            "Using pool size: 8\n",
            "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.09969 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "square function: This function computes the square of a given number.\n",
        "\n",
        "Pool size: Different pool sizes (2, 4, and 8) are tested to measure the performance.\n",
        "\n",
        "pool.map(): It applies the square function to each number in the list, distributing the tasks across the pool processes in parallel.\n",
        "\n",
        "Time measurement: time.time() is used to measure the start and end times of the computation to calculate how long it takes.\n",
        "\n",
        "The program demonstrates how using a higher number of processes can potentially reduce the computation time for parallel tasks.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "___________________________________________________________________________"
      ],
      "metadata": {
        "id": "mSWM9wRCqrTs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RemwzPpUrOxE"
      }
    }
  ]
}